{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "# <center> #DHBSI 2016: Computational Text Analysis </center>\n",
    "\n",
    "## <center> Laura Nelson <br/> <em>Postdoctoral Fellow | Digital Humanities @ Berkeley | Berkeley Institute for Data Science </em> </center>\n",
    "\n",
    "## <center> Teddy Roland <br/> <em> Coordinator, Digital Humanities @ Berkeley <br/> Lecturer, UC Berkeley </em> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Summary </center>\n",
    "## <center> Text Analysis Demystified </center>\n",
    "### <center> It's Just Counting! <br/> </center>\n",
    "![Counting](Text_Counting.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> The Dark Side of DH: An Invitation\n",
    "![Dark Side](Dark_Side.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Text Analysis in Research </center>\n",
    "![Interpretive Moments](Text_Analysis_In_Reearch.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Lessons </center>\n",
    "### <center> Our workshop included 5 days and 7 lessons to learn how counting, sometimes creative counting, can amplify and augment close readings of text </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Lesson 1: Introduction to Natural Language Processing\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "punctuations = list(string.punctuation)\n",
    "\n",
    "#read the two text files from your hard drive, assign first mystery text to variable 'text1' and second mystery text to variable 'text2'\n",
    "text1 = open('../01-Intro-to-NLP/text1.txt').read()\n",
    "text2 = open('../01-Intro-to-NLP/text2.txt').read()\n",
    "\n",
    "###word frequencies\n",
    "\n",
    "#tokenize texts\n",
    "text1_tokens = word_tokenize(text1)\n",
    "text2_tokens = word_tokenize(text2)\n",
    "\n",
    "#pre-process for word frequency\n",
    "#lowercase\n",
    "text1_tokens_lc = [word.lower() for word in text1_tokens]\n",
    "text2_tokens_lc = [word.lower() for word in text2_tokens]\n",
    "\n",
    "#remove stopwords\n",
    "text1_tokens_clean = [word for word in text1_tokens_lc if word not in stopwords.words('english')]\n",
    "text2_tokens_clean = [word for word in text2_tokens_lc if word not in stopwords.words('english')]\n",
    "\n",
    "#remove punctuation using the list of punctuation from the string pacage\n",
    "text1_tokens_clean = [word for word in text1_tokens_clean if word not in punctuations]\n",
    "text2_tokens_clean = [word for word in text2_tokens_clean if word not in punctuations]\n",
    "\n",
    "#frequency distribution\n",
    "text1_word_frequency = nltk.FreqDist(text1_tokens_clean)\n",
    "text2_word_frequency = nltk.FreqDist(text2_tokens_clean)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Frequent Words for Text1\")\n",
    "print(\"________________________\")\n",
    "for word in text1_word_frequency.most_common(20):\n",
    "    print(word[0])\n",
    "print()\n",
    "print(\"Frequent Words for Text2\")\n",
    "print(\"________________________\")\n",
    "for word in text2_word_frequency.most_common(20):\n",
    "    print(word[0])\n",
    "    \n",
    "    \n",
    "###Can you guess the novel from most frequent words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Lesson 2: Basics of Python\n",
    "###Nothing to see here, folks\n",
    "\n",
    "\n",
    "##Lesson 3: Operationalizing\n",
    "import pandas\n",
    "dialogue_df = pandas.read_csv('../03-Operationalizing/antigone_dialogue.csv', index_col=0)\n",
    "dialogue_tokens = [character.split() for character in dialogue_df['DIALOGUE']]\n",
    "dialogue_len = [len(tokens) for tokens in dialogue_tokens]\n",
    "dialogue_df['WORDS_SPOKEN'] = dialogue_len\n",
    "dialogue_df = dialogue_df.sort_values('WORDS_SPOKEN', ascending = False)\n",
    "# Let's visualize!\n",
    "\n",
    "# Tells Jupyter to produce images in notebook\n",
    "% pylab inline\n",
    "\n",
    "# Makes images look good\n",
    "style.use('ggplot')\n",
    "dialogue_df['WORDS_SPOKEN'].plot(kind='bar')\n",
    "\n",
    "###Who is the main protagonist? Maybe not Antigone?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lesson 4: Discriminating Words\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pandas.read_csv(\"../04-Discriminating-Words/BDHSI2016_music_reviews.csv\", sep = '\\t')\n",
    "\n",
    "tfidfvec = TfidfVectorizer()\n",
    "#create the dtm, but with cells weigthed by the tf-idf score.\n",
    "dtm_tfidf_df = pandas.DataFrame(tfidfvec.fit_transform(df.body).toarray(), columns=tfidfvec.get_feature_names(), index = df.index)\n",
    "\n",
    "df_genre = df['genre'].to_frame()\n",
    "merged_df = df_genre.join(dtm_tfidf_df, how = 'right', lsuffix='_x')\n",
    "\n",
    "#pull out the reviews for three genres, Rap, Alternative/Indie Rock, and Jazz\n",
    "dtm_rap = merged_df[merged_df['genre_x']==\"Rap\"]\n",
    "dtm_indie = merged_df[merged_df['genre_x']==\"Alternative/Indie Rock\"]\n",
    "dtm_jazz = merged_df[merged_df['genre_x']==\"Jazz\"]\n",
    "\n",
    "#print the words with the highest tf-idf scores for each genre\n",
    "print(\"Rap Words\")\n",
    "print(dtm_rap.max(numeric_only=True).sort_values(ascending=False)[0:20])\n",
    "print()\n",
    "print(\"Indie Words\")\n",
    "print(dtm_indie.max(numeric_only=True).sort_values(ascending=False)[0:20])\n",
    "print()\n",
    "print(\"Jazz Words\")\n",
    "print(dtm_jazz.max(numeric_only=True).sort_values(ascending=False)[0:20])\n",
    "\n",
    "###What words are distinct to reviews of Rap albums, Indie albums, and Jazz albums?\n",
    "##Notice the word weights for the Rap albums compared to others. Are these reviews more different than other reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Lesson 5: Sentiment Analysis using the Dictionary Method\n",
    "\n",
    "pos_sent = open(\"../05-Dictionary-Method/positive_words.txt\").read()\n",
    "neg_sent = open(\"../05-Dictionary-Method/negative_words.txt\").read()\n",
    "\n",
    "positive_words=pos_sent.split('\\n')\n",
    "negative_words=neg_sent.split('\\n')\n",
    "\n",
    "text1_pos = [word for word in text1_tokens_clean if word in positive_words]\n",
    "text2_pos = [word for word in text2_tokens_clean if word in positive_words]\n",
    "\n",
    "text1_neg = [word for word in text1_tokens if word in negative_words]\n",
    "text2_neg = [word for word in text2_tokens if word in negative_words]\n",
    "\n",
    "print(\"Postive words in Melville\")\n",
    "print(len(text1_pos)/len(text1_tokens))\n",
    "print()\n",
    "print(\"Negative words in Melville\")\n",
    "print(len(text1_neg)/len(text1_tokens))\n",
    "print()\n",
    "print(\"Postive words in Austen\")\n",
    "print(len(text2_pos)/len(text2_tokens))\n",
    "print()\n",
    "print(\"Negative words in Austen\")\n",
    "print(len(text2_neg)/len(text2_tokens))\n",
    "\n",
    "###Who is more postive, Melville or Austen?\n",
    "##Melville has a similar precentage of postive and negative words (a whale is a whale, neither good nor bad)\n",
    "##Austen is decidedly more positive than negative (it's the gentleman thing to do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lesson 6: Literary Distinction\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lesson 6: Topic Modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
